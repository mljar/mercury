{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93607524-8bc9-4b48-b162-ec46a5f312c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import mercury as mr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3ab52bf-0f50-4368-aeb0-bf6abce2429a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list with all user and assistant messages\n",
    "messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "036b7382-b1a4-4478-b479-ba12a13852b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ea3fba05e3344b187e81e046220b05c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='\\n            <div style=\"\\n              color:#b5b5b5;\\n              text-align:â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea1e2483e16e4fe2a7fc2cb5c60a7cb8",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "<mercury.chat.chat.ScrollHelper object at 0x7764c52f2950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# place to display messages\n",
    "chat = mr.Chat(placeholder=\"ðŸ’¬ Start conversation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc24fc5e-23ce-4791-99f6-a4eeb3672ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/mercury+json": {
       "model_id": "131b68a2f56b4ca4875c7b8c0626b5bf",
       "position": "bottom",
       "widget": "ChatInputWidget"
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "131b68a2f56b4ca4875c7b8c0626b5bf",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "<mercury.chat.chatinput.ChatInputWidget object at 0x7764c549f610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# user input\n",
    "prompt = mr.ChatInput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d37cebc-33a0-4ec5-a367-e204a7197883",
   "metadata": {},
   "outputs": [],
   "source": [
    "if prompt.value:\n",
    "    # create user message\n",
    "    usr_msg = mr.Message(markdown=prompt.value, role=\"user\")\n",
    "    # display user message in the chat\n",
    "    chat.add(usr_msg)\n",
    "    # save in messages list\n",
    "    messages += [{'role': 'user', 'content': prompt.value}]\n",
    "\n",
    "    # call local LLM\n",
    "    stream = ollama.chat(\n",
    "      model='gpt-oss:20b',\n",
    "      messages=messages,\n",
    "      stream=True,\n",
    "    )\n",
    "\n",
    "    # create assistant message\n",
    "    ai_msg = mr.Message(role=\"assistant\", emoji=\"ðŸ¤–\")\n",
    "    # display assistant message in the chat\n",
    "    chat.add(ai_msg)\n",
    "\n",
    "    # stream with response\n",
    "    content = \"\"\n",
    "    for chunk in stream:\n",
    "        ai_msg.append_markdown(chunk.message.content)\n",
    "        content += chunk.message.content\n",
    "\n",
    "    # save assistant response\n",
    "    messages += [{'role': 'assistant', 'content': content}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bd1e7f-736a-4af3-b102-551e1682a32f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "mercury": {
   "description": "Streaming example",
   "thumbnail_bg": "#5dcefe",
   "thumbnail_text": "ðŸ¦™",
   "title": "Ollama streaming"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0cd0874bac744d26b8465d6a4512fec5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "131b68a2f56b4ca4875c7b8c0626b5bf": {
      "model_module": "anywidget",
      "model_module_version": "~0.9.*",
      "model_name": "AnyModel",
      "state": {
       "_anywidget_id": "mercury.chat.chatinput.ChatInputWidget",
       "_css": "\n    .mljar-chatinput-container {\n        display: flex;\n        flex-direction: row;\n        align-items: center;\n        width: 100%;\n        min-width: 160px;\n        box-sizing: border-box;\n        gap: 8px;\n        font-family: Arial, sans-serif;\n        font-size: 14px;\n        color: #222;\n        padding-top: 8px;\n        padding-bottom: 8px;\n    }\n\n    .mljar-chatinput-input {\n        flex: 1 1 auto;\n        width: 100%;\n        border: 1px solid #ccc;\n        border-radius: 6px;\n        padding: 6px 10px;\n        min-height: 1.6em;\n        background: #fff;\n        color: #222;\n        box-sizing: border-box;\n        padding: 10px;\n        font-size: 0.9rem;\n    }\n\n    .mljar-chatinput-input:focus {\n        outline: none;\n        border-color: #007bff;\n    }\n\n    .mljar-chatinput-button {\n        flex: 0 0 auto;\n        border: none;\n        border-radius: 6px !important;\n        min-height: 1.6em;\n        cursor: pointer;\n        background: #007bff;\n        color: #fff;\n        font-weight: bold;\n        padding: 11px;\n        padding-left: 18px;\n        padding-right: 18px;\n    }\n\n    .mljar-chatinput-button:hover {\n        filter: brightness(0.95);\n    }\n    ",
       "_esm": "\n    function render({ model, el }) {\n      el.style.flex = \"0 0 auto\";\n      const container = document.createElement(\"div\");\n      container.classList.add(\"mljar-chatinput-container\");\n\n      const input = document.createElement(\"input\");\n      input.type = \"text\";\n      input.placeholder = model.get(\"placeholder\") || \"Type a message...\";\n      input.value = model.get(\"value\") || \"\";\n      input.classList.add(\"mljar-chatinput-input\");\n\n      const btn = document.createElement(\"button\");\n      btn.type = \"button\";\n      btn.classList.add(\"mljar-chatinput-button\");\n      btn.textContent = model.get(\"button_icon\") || \" âž¤ \";\n      btn.setAttribute(\"aria-label\", \"Send message\");\n\n      container.appendChild(input);\n      container.appendChild(btn);\n      el.appendChild(container);\n\n      let lastModelValue = model.get(\"value\") ?? \"\";\n\n      model.on(\"change:value\", () => {\n        const newVal = model.get(\"value\") ?? \"\";\n\n        // Only update the visible input if the user hasn't typed since\n        // the last time we applied a model value.\n        const userHasTyped = input.value !== lastModelValue;\n        if (!userHasTyped) {\n            input.value = newVal;\n        }\n\n        lastModelValue = newVal;\n      });\n      \n      const sendMessage = () => {\n        const msg = (input.value || \"\").trim();\n        if (!msg) return;\n\n        model.set(\"submitted\", msg);\n        model.set(\"value\", msg);\n        // After submission we clear the input, but the model value becomes msg.\n        // Track it so subsequent model changes don't clobber a new draft.\n        lastModelValue = msg;\n        input.value = \"\";\n        model.save_changes();\n      };\n\n      btn.addEventListener(\"click\", sendMessage);\n\n      input.addEventListener(\"keydown\", (ev) => {\n        const sendOnEnter = !!model.get(\"send_on_enter\");\n        if (!sendOnEnter) return;\n        if (ev.key === \"Enter\" && !ev.shiftKey) {\n          ev.preventDefault();\n          sendMessage();\n        }\n      });\n    }\n    export default { render };\n    ",
       "_model_module": "anywidget",
       "_model_module_version": "~0.9.*",
       "_model_name": "AnyModel",
       "_view_module": "anywidget",
       "_view_module_version": "~0.9.*",
       "_view_name": "AnyView",
       "button_icon": "âž¤",
       "cell_id": "",
       "layout": "IPY_MODEL_cf255323d2fd400aa591f0c005db03f6",
       "placeholder": "Type a message...",
       "position": "bottom",
       "send_on_enter": true,
       "submitted": "who are you?",
       "value": ""
      }
     },
     "15a1e537d4e14b8898b9d5e72df10f4b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_368eb8b238c541e6ace6677638c58685",
        "IPY_MODEL_5b10d554b4174caebb138fa5d0db3de9"
       ],
       "layout": "IPY_MODEL_977c317839a0441c921c1dc0f5200a98"
      }
     },
     "241095d9d3ce404488a1eba6fcdf2304": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "align_self": "flex-start",
       "margin": "0 8px 8px 0"
      }
     },
     "2bf9ebc6ac9642e4be221bfb72582a55": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2ddf05defb8e40ba9af1373f4d114db8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "align_self": "flex-start",
       "margin": "8px 0 0 0"
      }
     },
     "368eb8b238c541e6ace6677638c58685": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_3efc7796a4d6454f97d9b23b20f8866b",
       "style": "IPY_MODEL_2bf9ebc6ac9642e4be221bfb72582a55",
       "value": "<div style=\"width:36px;height:36px;background:#eeeeee;border-radius:12px;display:flex;align-items:center;justify-content:center;box-shadow:0 1px 4px rgba(60,60,60,0.10);\"><span style=\"font-size:18px;line-height:1;\">ðŸ¤–</span></div>"
      }
     },
     "37f587f9fe7a42ee815b3784919397e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_97eea583aa4146e49cf93bc1dedf6a5b",
        "IPY_MODEL_9ac2009815b64ff69f3cc99c85277a72"
       ],
       "layout": "IPY_MODEL_c21f258b00904e659320709cddab0e76"
      }
     },
     "3efc7796a4d6454f97d9b23b20f8866b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "align_self": "flex-start",
       "margin": "0 8px 8px 0"
      }
     },
     "412aa99f05b54246b47a15d44c81978d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "padding": "4px",
       "width": "100%"
      }
     },
     "4ea3fba05e3344b187e81e046220b05c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_37f587f9fe7a42ee815b3784919397e8",
        "IPY_MODEL_15a1e537d4e14b8898b9d5e72df10f4b"
       ],
       "layout": "IPY_MODEL_412aa99f05b54246b47a15d44c81978d"
      }
     },
     "5b10d554b4174caebb138fa5d0db3de9": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [
        "mljar-chat-msg"
       ],
       "layout": "IPY_MODEL_8d5701366beb4a6295264790a861cef5",
       "outputs": [
        {
         "data": {
          "text/markdown": "Iâ€™m ChatGPT, a large language model created by OpenAI. Iâ€™m built on the GPTâ€‘4 architecture and trained on a wide range of text to help answer questions, brainstorm ideas, explain concepts, and more. I donâ€™t have personal experiences or emotions, but I can provide information, suggestions, and conversation across many topics. How can I help you today?",
          "text/plain": "<IPython.core.display.Markdown object>"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ]
      }
     },
     "71d92aca9b8f41b68ed2140f6489f9d6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_9f5e48227c3743af9bb7882c464e07ef",
       "style": "IPY_MODEL_0cd0874bac744d26b8465d6a4512fec5",
       "value": "\n            <div style=\"\n              color:#b5b5b5;\n              text-align:center;\n              padding:40px 0;\n              font-size:1.1em;\n              background:#fff;\n            \">ðŸ’¬ Start conversation</div>\n            "
      }
     },
     "8d5701366beb4a6295264790a861cef5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "align_self": "flex-start",
       "margin": "8px 0 0 0"
      }
     },
     "977c317839a0441c921c1dc0f5200a98": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "align_items": "flex-start"
      }
     },
     "97eea583aa4146e49cf93bc1dedf6a5b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_241095d9d3ce404488a1eba6fcdf2304",
       "style": "IPY_MODEL_f6fa9301e9324448851d1a274fb2ed20",
       "value": "<div style=\"width:36px;height:36px;background:#84c4ff;border-radius:12px;display:flex;align-items:center;justify-content:center;box-shadow:0 1px 4px rgba(60,60,60,0.10);\"><span style=\"font-size:18px;line-height:1;\">ðŸ‘¤</span></div>"
      }
     },
     "9ac2009815b64ff69f3cc99c85277a72": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [
        "mljar-chat-msg"
       ],
       "layout": "IPY_MODEL_2ddf05defb8e40ba9af1373f4d114db8",
       "outputs": [
        {
         "data": {
          "text/markdown": "who are you?",
          "text/plain": "<IPython.core.display.Markdown object>"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ]
      }
     },
     "9f5e48227c3743af9bb7882c464e07ef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c21f258b00904e659320709cddab0e76": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "align_items": "flex-start"
      }
     },
     "cf255323d2fd400aa591f0c005db03f6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e64341b2cf374c63bb409a5fe50f0aef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ea1e2483e16e4fe2a7fc2cb5c60a7cb8": {
      "model_module": "anywidget",
      "model_module_version": "~0.9.*",
      "model_name": "AnyModel",
      "state": {
       "_anywidget_id": "mercury.chat.chat.ScrollHelper",
       "_css": "\n    .mljar-chat-scroll-helper {\n        display: none;\n    }\n    ",
       "_esm": "\nfunction render({ model, el }) {\n  const LOG_PREFIX = \"[ScrollHelper]\";\n  const MSG_CLASS = model.get(\"msg_css_class\") || \"mljar-chat-msg\";\n\n  // Just in case, hide the helper element itself\n  el.classList.add(\"mljar-chat-scroll-helper\");\n\n  function isScrollable(elem) {\n    if (!elem) return false;\n    const cs = getComputedStyle(elem);\n    const oy = cs.overflowY;\n    const o = cs.overflow;\n    const canScroll = elem.scrollHeight > (elem.clientHeight + 2);\n    return (\n      canScroll &&\n      (oy === \"auto\" || oy === \"scroll\" || o === \"auto\" || o === \"scroll\")\n    );\n  }\n\n  function findScrollableWithin(rootEl) {\n    if (!rootEl) return null;\n    if (isScrollable(rootEl)) return rootEl;\n\n    const walker = document.createTreeWalker(\n      rootEl,\n      NodeFilter.SHOW_ELEMENT,\n      null\n    );\n    let n = walker.currentNode;\n    while ((n = walker.nextNode())) {\n      if (isScrollable(n)) return n;\n    }\n    return null;\n  }\n\n  function getScrollableAncestor(node) {\n    let cur = node && node.parentElement;\n    while (cur) {\n      if (isScrollable(cur)) return cur;\n      cur = cur.parentElement;\n    }\n    return null;\n  }\n\n  function scrollIntoContainer(elem, container) {\n    if (!elem || !container) return;\n    let y = 0;\n    let n = elem;\n    while (n && n !== container) {\n      y += n.offsetTop || 0;\n      n = n.offsetParent;\n    }\n    const target = Math.max(\n      0,\n      y - (container.clientHeight - elem.clientHeight) + 16\n    );\n    container.scrollTop = target;\n  }\n\n  function scrollPageFallback(elem) {\n    try {\n      elem.scrollIntoView({ behavior: \"smooth\", block: \"end\" });\n    } catch (e) {\n      // ignore\n    }\n  }\n\n  function autoScroll() {\n    const msgs = document.getElementsByClassName(MSG_CLASS);\n    if (!msgs || !msgs.length) return;\n    const last = msgs[msgs.length - 1];\n\n    const selector =\n      model.get(\"scroll_container_selector\") ||\n      \"#mercury-main-panel, .mercury-main-panel\";\n\n    let pref = null;\n    try {\n      pref = document.querySelector(selector);\n    } catch (e) {\n      console.warn(LOG_PREFIX, \"bad selector\", selector, e);\n    }\n\n    const scroller =\n      findScrollableWithin(pref) ||\n      getScrollableAncestor(last) ||\n      document.scrollingElement ||\n      document.documentElement;\n\n    if (scroller) {\n      scrollIntoContainer(last, scroller);\n    } else {\n      scrollPageFallback(last);\n    }\n  }\n\n  function scheduleScroll() {\n    // Give big outputs (plots, images) a moment to layout\n    requestAnimationFrame(() => {\n      setTimeout(autoScroll, 100);\n    });\n  }\n\n  // initial scroll attempt (in case messages already present)\n  scheduleScroll();\n\n  // each time Python bumps `tick`, schedule scroll\n  model.on(\"change:tick\", scheduleScroll);\n}\nexport default { render };\n    ",
       "_model_module": "anywidget",
       "_model_module_version": "~0.9.*",
       "_model_name": "AnyModel",
       "_view_module": "anywidget",
       "_view_module_version": "~0.9.*",
       "_view_name": "AnyView",
       "layout": "IPY_MODEL_e64341b2cf374c63bb409a5fe50f0aef",
       "msg_css_class": "mljar-chat-msg",
       "scroll_container_selector": "#mercury-main-panel, .mercury-main-panel",
       "tick": 2
      }
     },
     "f6fa9301e9324448851d1a274fb2ed20": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
