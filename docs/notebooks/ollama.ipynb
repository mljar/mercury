{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45cd246b-995e-4cef-9c97-89db0f92013d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import asyncio\n",
    "_ = load_dotenv(\".ollama.env\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b80b9bb4-eb45-4f49-a01a-6299126af747",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import AsyncClient\n",
    "\n",
    "client = AsyncClient(\n",
    "    host=\"https://ollama.com\",\n",
    "    headers={'Authorization': 'Bearer ' + os.environ.get('OLLAMA_API_KEY')}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2d0446d-93ff-42d2-98b8-a186c97afb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"gpt-oss:20b\", \"ministral-3:14b\"] # \"qwen3-vl:235b-cloud\", \"deepseek-v3.2\", "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5908a017-c067-4ea4-b7cb-c7c84e22fd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mercury import Columns, Chat, Message, ChatInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31a6880e-85ad-4e8e-9249-6d594632330b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    .mljar-column {\n",
       "        border-radius: 4px !important;\n",
       "    }\n",
       "    </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/mercury+json": {
       "model_id": "4bba275b40954100bccf592b9c742d39",
       "position": "inline",
       "widget": "ColumnsBox"
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bba275b40954100bccf592b9c742d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ColumnsBox(children=(ColumnOutput(layout=Layout(border_bottom='1px solid lightgray', border_left='1px solid liâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "left, right = Columns(2, border=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f10b661-286a-4f2b-9686-5e985a07d5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with left:\n",
    "    left_chat = Chat()\n",
    "with right:\n",
    "    right_chat = Chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fba930f-b465-465f-8042-e364fd0a28d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8b6f3e-3f93-4052-8b60-64de34e8e543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a674c75-efd3-41cc-b352-2ac0117b0b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of messages\n",
    "left_messages = []\n",
    "right_messages = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa354c3-5614-4192-8afa-1b58b4cfd8ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "75f5f460-b2f9-4377-ae61-30598761219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def ollama_responder(model, messages):\n",
    "    # chat(...) is a coroutine â€“ we must await it\n",
    "    stream = await client.chat(model=model, messages=messages, stream=True)\n",
    "    # now 'stream' is an async iterator of parts\n",
    "    async for part in stream:\n",
    "        yield part[\"message\"][\"content\"]\n",
    "        \n",
    "\n",
    "        \n",
    "async def stream_responder(model, messages, bot_msg):\n",
    "    print(\"model\", model)\n",
    "    async for chunk in ollama_responder(model, messages):\n",
    "        bot_msg.append_markdown(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90a48ee5-ea76-4d44-91da-b59e0c215dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def handle_submit(msg):\n",
    "\n",
    "    # User prompt\n",
    "    user_msg = Message(role=\"user\", emoji=\"ðŸ‘¤\")\n",
    "    user_msg.set_message(markdown=msg)\n",
    "    left_chat.add(user_msg)\n",
    "    right_chat.add(user_msg)\n",
    "\n",
    "    # Left AI response shell\n",
    "    left_bot_msg = Message(role=\"assistant\", emoji=\"ðŸ¤–\")\n",
    "    left_bot_msg.set_gradient_text(\"Thinking hard ðŸ¤”\")\n",
    "    left_chat.add(left_bot_msg)\n",
    "\n",
    "    # Right AI response shell\n",
    "    right_bot_msg = Message(role=\"assistant\", emoji=\"ðŸ¤–\")\n",
    "    right_bot_msg.set_bouncing_text(\"Thinking hard ðŸ¤”\")\n",
    "    right_chat.add(right_bot_msg)\n",
    "\n",
    "    messages = [\n",
    "      {\n",
    "        'role': 'user',\n",
    "        'content': 'Why is the sky blue? max 2 sentences',\n",
    "      },\n",
    "    ]\n",
    "    # Start both streams in parallel\n",
    "    await asyncio.gather(\n",
    "        stream_responder(models[0], messages, left_bot_msg),\n",
    "        stream_responder(models[1], messages, right_bot_msg),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7959511a-24db-47df-b731-1649a82825d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/mercury+json": {
       "model_id": "e808f6c0ee5e4be497abd2ade02a8d76",
       "position": "bottom",
       "widget": "ChatInputWidget"
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e808f6c0ee5e4be497abd2ade02a8d76",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "<mercury.chat.chatinput.ChatInputWidget object at 0x7f7103a4efd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = ChatInput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd874c4-4612-4bba-98e6-83575e5dd576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "badcaaa3-090a-4e54-8ca4-cff415258b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model gpt-oss:20b\n",
      "model ministral-3:14b\n"
     ]
    }
   ],
   "source": [
    "if prompt.value:\n",
    "    await handle_submit(prompt.value)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1360154-d43f-492a-964b-67ed216db32e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0267ac19-1668-44ac-9b31-d45b5763d6fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
